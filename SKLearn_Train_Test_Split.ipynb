{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SKLearn Train Test Split Workout**"
      ],
      "metadata": {
        "id": "fVucZf6iAQW7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m3-IsuSEAAGs"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sklearn library provides the iris dataset, which is a commonly used dataset for classification problems. This dataset has 150 samples. To get the dataset, we can write the following code in a new cell.\n"
      ],
      "metadata": {
        "id": "Az-OluWFAGdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load iris dataset\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "5NCjtzS3AFnL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate attributes and labels on iris dataset\n",
        "x=iris.data\n",
        "y=iris.target"
      ],
      "metadata": {
        "id": "GVOBQE0wAchu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create the train set and test set, we just need to call the train_test_split function. Train_test_split has parameters x which is the attribute of the dataset, y which is the target of the dataset, and test_size which is the percentage of the test set from the whole dataset. Train_test_split returns 4 values, namely, attributes of the train set, attributes of the test set, target of the train set, and target of the test set."
      ],
      "metadata": {
        "id": "X8ZPPyr9An5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# divide the dataset into training and testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "MveRU6DtAf8L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we print the length of x_test, we can see that the length of the test set attribute is **30 samples**, according to the parameter we entered in the train_test_split function which is 0.2 or 20% of 150 samples. The code to print the length of x_test is as below."
      ],
      "metadata": {
        "id": "Lhwg8xAgA2GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the length/number of data in x_test\n",
        "len(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7UsvEUIAv2A",
        "outputId": "3ef50d9d-b775-4645-8c65-3f3106262a02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}